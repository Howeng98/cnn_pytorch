{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E31du8Z5zvfN"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "import gc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE5rnh-w9Haz"
      },
      "source": [
        "!nvidia-smi\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOvSO7jjzx2v"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08VgZP8ozz_Y"
      },
      "source": [
        "# Hyper Parameters\n",
        "EPOCH = 10\n",
        "BATCH_SIZE = 64\n",
        "LR = 0.01\n",
        "MOMENTUM = 0.9\n",
        "num_classes = 10\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "DOWNLOAD = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2pMAwFC0Auy"
      },
      "source": [
        "# Transform\n",
        "transform = transforms.Compose(\n",
        "                [\n",
        "                 transforms.Resize(size=(224,224)),\n",
        "                 transforms.ToTensor(),\n",
        "                 transforms.Normalize((0.5,), (0.5,)),                 \n",
        "                #  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                 transforms.RandomHorizontalFlip(),\n",
        "                ]\n",
        "                )\n",
        "\n",
        "# Data\n",
        "train_dataset = datasets.CIFAR10(root='/dataset', train=True, download=DOWNLOAD, transform=transform)\n",
        "valid_dataset = datasets.CIFAR10(root='/dataset', train=False, download=DOWNLOAD, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reWTv5P0NqEh"
      },
      "source": [
        "class Vgg16(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Vgg16, self).__init__()\n",
        "        #block 1\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        #block 2\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        #block 3\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        #block 4\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        #block 5\n",
        "        self.block5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.MaxPool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.classfier = nn.Sequential(\n",
        "            nn.Linear(in_features=7*7*512, out_features=4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.4),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.4),\n",
        "            nn.Linear(in_features=4096, out_features=num_classes),            \n",
        "        )\n",
        "                        \n",
        "    def forward(self, x):          \n",
        "          x = self.block1(x)          \n",
        "          x = self.MaxPool2d(x)          \n",
        "          x = self.block2(x)          \n",
        "          x = self.MaxPool2d(x)          \n",
        "          x = self.block3(x)          \n",
        "          x = self.MaxPool2d(x)          \n",
        "          x = self.block4(x)          \n",
        "          x = self.MaxPool2d(x)          \n",
        "          x = self.block5(x)          \n",
        "          x = self.MaxPool2d(x)                \n",
        "          x = torch.flatten(x,1)\n",
        "          x = self.classfier(x)\n",
        "        \n",
        "          return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEgGWNFG7z-z"
      },
      "source": [
        "model = Vgg16(num_classes)\n",
        "model = model.to(device)\n",
        "print(model)\n",
        "summary(model, (3,224,224))\n",
        "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4YxWiOi4ibk"
      },
      "source": [
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)    \n",
        "    model.train()\n",
        "    \n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0            \n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):        \n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "                \n",
        "        optimizer.zero_grad()        \n",
        "        outputs = model(inputs)\n",
        "                \n",
        "        loss = criterion(outputs, targets)                \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            train_acc_per_epoch = 100 * (correct / float(total))\n",
        "            train_loss_per_epoch = train_loss / total\n",
        "            print(\"Train Epoch: {}/{} [iter： {:03d}/{:03d}], acc： {:.6f}, loss： {:.6f}\".format(\n",
        "               epoch, EPOCH, batch_idx+1, len(train_loader),\n",
        "               train_acc_per_epoch,\n",
        "               train_loss_per_epoch))\n",
        "    return train_acc_per_epoch, train_loss_per_epoch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpKCLlBg6Gzb"
      },
      "source": [
        "def test(epoch):        \n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(valid_loader):            \n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            \n",
        "            outputs = model(inputs)            \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            if batch_idx % 100 == 0:     \n",
        "              test_acc_per_epoch = 100 * (correct / float(total))\n",
        "              test_loss_per_epoch = test_loss / total\n",
        "              print(\"Valid Epoch: {}/{} [iter： {:03d}/{:03d}], acc： {:.6f}, loss： {:.6f}\".format(\n",
        "                epoch, EPOCH, batch_idx+1, len(valid_loader),                \n",
        "                test_acc_per_epoch,\n",
        "                test_loss_per_epoch))                \n",
        "            \n",
        "    return test_acc_per_epoch, test_loss_per_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfjeuVNo6H7r"
      },
      "source": [
        "def training_loop():\n",
        "    # set objects for storing metrics\n",
        "    total_train_loss = []\n",
        "    total_valid_loss = []\n",
        "    total_train_accuracy = []\n",
        "    total_valid_accuracy = []\n",
        " \n",
        "    # Train model\n",
        "    for epoch in range(1,EPOCH+1):\n",
        "        # training\n",
        "        \n",
        "        train_acc_, train_loss_ = train(epoch)\n",
        "        total_train_accuracy.append(train_acc_)\n",
        "        total_train_loss.append(train_loss_)\n",
        "        \n",
        "        valid_acc_, valid_loss_ = test(epoch)        \n",
        "        total_valid_accuracy.append(valid_acc_)\n",
        "        total_valid_loss.append(valid_loss_)\n",
        "\n",
        "        print('==========================================================================')\n",
        "        print(\"Epoch: {:05d}/{:05d}， Train acc： {:.6f}， Train loss： {:.6f}， Valid acc： {:.6f}， Valid loss： {:.6f}\".format(\n",
        "               epoch, EPOCH, \n",
        "               train_acc_, train_loss_,\n",
        "               valid_acc_, valid_loss_))\n",
        "        print('==========================================================================')\n",
        "\n",
        "    # print(\"====== END ==========\")\n",
        "\n",
        "    return total_train_loss, total_valid_loss, total_train_accuracy, total_valid_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZvp4Gf8V6aK"
      },
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnOAmPUUJPAd"
      },
      "source": [
        "total_train_loss, total_valid_loss, total_train_accuracy, total_valid_accuracy = training_loop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV2Zx0P-6KDX"
      },
      "source": [
        "def plot_result(total_train, total_valid, label):\n",
        "    plt.plot(range(1,EPOCH+1), total_train, 'b-', label=f'Training_{label}')\n",
        "    plt.plot(range(1,EPOCH+1), total_valid, 'g-', label=f'validation_{label}')\n",
        "    plt.title(f'Training & Validation {label}')\n",
        "    plt.xlabel('Number of epochs')\n",
        "    plt.ylabel(f'{label}')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhmLNAJS6M83"
      },
      "source": [
        "plot_result(total_train_accuracy, total_valid_accuracy, 'accuracy')\n",
        "plot_result(total_train_loss, total_valid_loss, 'loss')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}